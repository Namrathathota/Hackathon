# -*- coding: utf-8 -*-
"""Image Detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S5PazE-nt261Q8s_N0-q4oWZkAvU7ZyP
"""

# Step 1: Install DeepFace
!pip install deepface -q

# Step 2: Import required libraries
import cv2
import numpy as np
import matplotlib.pyplot as plt
from deepface import DeepFace
from google.colab import files

# Step 3: Define emotion colors and responses
emotion_colors = {
    'happy': (0, 255, 0),       # Green
    'sad': (255, 0, 0),         # Blue
    'angry': (0, 0, 255),       # Red
    'surprise': (255, 255, 0),  # Cyan
    'fear': (128, 0, 128),      # Purple
    'disgust': (0, 128, 128),   # Teal
    'neutral': (128, 128, 128), # Gray
    'confused': (0, 165, 255),  # Orange
    'dull': (160, 160, 160)     # Light Gray
}

emotion_responses = {
    'happy': "I'm glad you're enjoying the lesson!",
    'sad': "Looks like you're feeling a bit down. Let's go over it again.",
    'angry': "Frustrated? Let's break it down slowly.",
    'surprise': "Looks like something surprised you!",
    'fear': "Don't worry, I'm here to help.",
    'disgust': "Something unclear? Let's clarify it.",
    'neutral': "Let's continue learning.",
    'confused': "You're confused. Let's go step by step.",
    'dull': "You seem unengaged. Let's make this fun!"
}

# Step 4: Upload and process image
uploaded = files.upload()

for filename in uploaded.keys():
    frame = cv2.imread(filename)

    if frame is None:
        print(f"‚ùå Error loading image: {filename}")
        continue

    try:
        results = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=True)

        for result in results:
            emotion = result['dominant_emotion']
            region = result['region']
            x, y, w, h = region['x'], region['y'], region['w'], region['h']
            color = emotion_colors.get(emotion.lower(), (255, 255, 255))
            response = emotion_responses.get(emotion.lower(), "Let's continue learning.")

            # Annotate the image
            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)
            cv2.putText(frame, emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)

            print(f"‚úÖ Detected Emotion: {emotion}")
            print("üí¨ Response:", response)

    except Exception as e:
        print("‚ùå Emotion detection failed:", str(e))

    # Convert image to RGB for display
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    plt.imshow(frame_rgb)
    plt.axis('off')
    plt.title("Detected Emotion with Response")
    plt.show()